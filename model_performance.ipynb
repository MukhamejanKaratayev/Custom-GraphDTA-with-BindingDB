{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.gat import GATNet\n",
    "from models.gat_gcn import GAT_GCN\n",
    "from models.gcn import GCNNet\n",
    "from models.ginconv import GINConvNet\n",
    "from lifelines.utils import concordance_index\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(model, device, loader):\n",
    "    model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            total_preds = torch.cat((total_preds.to(device), output), 0)\n",
    "            total_labels = torch.cat((total_labels.to(device), data.y.view(-1, 1).to(device)), 0)\n",
    "    return total_labels.cpu().numpy().flatten(),total_preds.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strange model is not strange - it is GOOD!!!\n",
    "datasets = [['davis','kiba','Ki','Kd','IC50', 'davis2', 'bdtdc_ic50','bdtdc_kd','bdtdc_ki','bindingdb_ic50','bindingdb_ki','bindingdb_kd'][-3]]\n",
    "modeling = [GINConvNet, GATNet, GAT_GCN, GCNNet][3]\n",
    "# model_st = modeling.__name__\n",
    "model_file_name = 'GraphDTA_Results/BindingDB/GCNNet/model_GCNNet_bindingdb_ic50.model' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing bindingdb_ic50\n",
      "Pre-processed data found: data/processed/bindingdb_ic50_test.pt, loading ...\n",
      "Make prediction for 219906 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:57<00:00,  7.41it/s]\n"
     ]
    }
   ],
   "source": [
    "TEST_BATCH_SIZE = 512\n",
    "for dataset in datasets:\n",
    "    print('Testing ' + dataset )\n",
    "    if dataset == 'Ki' or dataset == 'Kd' or dataset == 'IC50':\n",
    "        processed_data_file_test = 'data/bindingdb/processed/bindingDB_' + dataset + '_test.pt'\n",
    "    else:\n",
    "        processed_data_file_test = 'data/processed/' + dataset + '_test.pt'\n",
    "    if (not os.path.isfile(processed_data_file_test)):\n",
    "        print('please run create_data.py to prepare data in pytorch format!')\n",
    "    else:\n",
    "        if dataset == 'Ki' or dataset == 'Kd' or dataset == 'IC50':\n",
    "            test_data = TestbedDataset(root='data/bindingdb', dataset='bindingDB_'+dataset+'_test')\n",
    "        else:\n",
    "            test_data = TestbedDataset(root='data', dataset=dataset+'_test')\n",
    "        \n",
    "        # make data PyTorch mini-batch processing ready\n",
    "        test_loader = DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # training the model\n",
    "        \n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "        model = modeling()\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load(model_file_name,map_location='cuda:0'))\n",
    "\n",
    "        G,P = predicting(model, device, test_loader)\n",
    "        #ret = [rmse(G,P),mse(G,P),pearson(G,P),spearman(G,P),ci(G,P)]\n",
    "        ret = [rmse(G,P),mse(G,P),pearson(G,P),spearman(G,P),concordance_index(G,P)]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7003693730054906, 0.49051726, 0.8867872533814504, 0.8846194353694959, 0.858644259970728]\n"
     ]
    }
   ],
   "source": [
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "305324198e2c33e77a7ec7e7dd82a4ae7ad9a0e7d7c487c64915a854ddd80ed5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
